# yaml-language-server: $schema=https://taskfile.dev/schema.json
version: "3"

tasks:
  default: task --list --taskfile "{{.ROOT_DIR}}/.taskfiles/kubernetes/Taskfile.yaml"

  wait-for-ready:
    desc: Wait for the cluster to be ready and fix worker networking issues
    silent: true
    cmds:
      - |
        echo "â³ Waiting for {{.PROVIDER}} cluster..."

        # Set context and verify connection
        kubectl --kubeconfig {{.KUBECONFIG_PATH}} config use-context {{.PROVIDER}}-{{.CLUSTER_NAME}}

        # Give the API server a moment to initialize
        sleep 3

        # Wait for all nodes to be ready with timeout
        echo "  â±ï¸  Waiting up to 2 mins for all nodes to become ready..."
        kubectl --kubeconfig {{.KUBECONFIG_PATH}} wait --for=condition=Ready nodes --all --timeout=120s && echo "âœ… All nodes are ready" || echo "  âš ï¸  Warning: Some nodes still not ready"


  fetch-kubeconfig:
    desc: Fetch kubeconfig for the kubernetes cluster
    silent: true
    cmds:
      - |
        {{.PROVIDER_BINARY}} get kubeconfig --name {{.CLUSTER_NAME}} > {{.KUBECONFIG_PATH}}
      - chmod 0600 {{.KUBECONFIG_PATH}}
    preconditions:
      - msg: "{{.PROVIDER}} cluster {{.CLUSTER_NAME}} not found"
        sh: |
          {{.PROVIDER_BINARY}} get clusters | grep -q {{.CLUSTER_NAME}}
    status:
      - test -f {{.KUBECONFIG_PATH}} && grep -q {{.CLUSTER_NAME}} {{.KUBECONFIG_PATH}}

  setup-helm-repos:
    desc: Setup Helm repositories required by helmfile
    silent: true
    cmds:
      - echo "ðŸ”„ Setting up Helm repositories..."
      - |
        # Add repositories if they don't exist
        if ! helm repo list | grep -q "^traefik"; then
          echo "  ðŸ“¦ Adding traefik repository..."
          helm repo add traefik https://traefik.github.io/charts >/dev/null
        else
          echo "  ðŸ“¦ Updating traefik repository..."
          helm repo update traefik >/dev/null
        fi

        if ! helm repo list | grep -q "^groundhog2k"; then
          echo "  ðŸ“¦ Adding groundhog2k repository..."
          helm repo add groundhog2k https://groundhog2k.github.io/helm-charts/ >/dev/null
        else
          echo "  ðŸ“¦ Updating groundhog2k repository..."
          helm repo update groundhog2k >/dev/null
        fi

        if ! helm repo list | grep -q "^bjw-s-labs"; then
          echo "  ðŸ“¦ Adding bjw-s-labs repository..."
          helm repo add bjw-s-labs https://bjw-s-labs.github.io/helm-charts/ >/dev/null
        else
          echo "  ðŸ“¦ Updating bjw-s-labs repository..."
          helm repo update bjw-s-labs >/dev/null
        fi
      - echo "âœ… Helm repositories setup complete"
    status:
      - |
        # Check if all required repositories are present
        helm repo list | grep -q "traefik" && \
        helm repo list | grep -q "groundhog2k" && \
        helm repo list | grep -q "bjw-s-labs"

  setup-wildcard-cert:
    desc: Create wildcard TLS certificate secret for Traefik
    silent: true
    cmds:
      - echo "ðŸ”„ Creating wildcard TLS secret..."
      - |
        # Create traefik namespace if it doesn't exist
        kubectl --kubeconfig {{.KUBECONFIG_PATH}} create namespace traefik --dry-run=client -o yaml | kubectl --kubeconfig {{.KUBECONFIG_PATH}} apply -f -

        # Create wildcard TLS secret in traefik namespace
        kubectl --kubeconfig {{.KUBECONFIG_PATH}} create secret tls wildcard-tls \
          --namespace traefik \
          --cert={{.CERT_FILE}} \
          --key={{.KEY_FILE}} \
          --dry-run=client -o yaml | \
          kubectl --kubeconfig {{.KUBECONFIG_PATH}} apply -f -
      - echo "âœ… Wildcard TLS secret created"
    status:
      - kubectl --kubeconfig {{.KUBECONFIG_PATH}} get secret wildcard-tls -n traefik >/dev/null 2>&1



  deploy-services:
    desc: Deploy remaining services using helmfile
    silent: true
    deps: [setup-helm-repos, setup-wildcard-cert]
    cmds:
      - echo "ðŸ”„ Deploying services..."
      - |
        echo "  ðŸ“¦ Installing/upgrading Helm charts for enabled services..."
        HELM_BIN="$(mise which helm)"
        helmfile --helm-binary "$HELM_BIN" --file {{.K8S_DIR}}/config/helmfile.yaml \
          apply --kubeconfig {{.KUBECONFIG_PATH}} --skip-diff-on-install --suppress-diff
      - |
        # Apply Traefik TCP routes if any system services with TCP ports are enabled
        if [ -f "{{.K8S_DIR}}/config/traefik-tcp-routes.yaml" ] && [ -s "{{.K8S_DIR}}/config/traefik-tcp-routes.yaml" ]; then
          echo "  ðŸ”Œ Applying Traefik TCP routes for system services..."
          kubectl --kubeconfig {{.KUBECONFIG_PATH}} apply -f {{.K8S_DIR}}/config/traefik-tcp-routes.yaml
        fi
      - echo "âœ… Services deployed successfully"
    status:
      - |
        HELM_BIN="$(mise which helm)"
        helmfile --helm-binary "$HELM_BIN" --file {{.K8S_DIR}}/config/helmfile.yaml status --kubeconfig {{.KUBECONFIG_PATH}}

  label-worker-nodes:
    desc: "Label worker/agent nodes with node-role.kubernetes.io/worker=true"
    silent: true
    cmds:
      - |
        echo "ðŸ”„ Labeling worker nodes..."
        for ((i=0; i<{{.WORKERS}}; i++)); do
          if [ $i -eq 0 ]; then
            NODE_NAME="{{.CLUSTER_NAME}}-worker"
          else
            NODE_NAME="{{.CLUSTER_NAME}}-worker$((i+1))"
          fi
          if ! kubectl --kubeconfig {{.KUBECONFIG_PATH}} get node ${NODE_NAME} -o jsonpath='{.metadata.labels}' | grep -q 'node-role\.kubernetes\.io/worker'; then
            kubectl --kubeconfig {{.KUBECONFIG_PATH}} label node ${NODE_NAME} node-role.kubernetes.io/worker=true --overwrite
            echo "âœ… Labeled node ${NODE_NAME} as worker"
          else
            echo "â„¹ï¸ Node ${NODE_NAME} is already labeled as worker"
          fi
        done
    status:
      - |
        LABELED_COUNT=0
        for ((i=0; i<{{.WORKERS}}; i++)); do
          if [ $i -eq 0 ]; then
            NODE_NAME="{{.CLUSTER_NAME}}-worker"
          else
            NODE_NAME="{{.CLUSTER_NAME}}-worker$((i+1))"
          fi
          if kubectl --kubeconfig {{.KUBECONFIG_PATH}} get node ${NODE_NAME} -o jsonpath='{.metadata.labels}' | grep -q 'node-role\.kubernetes\.io/worker'; then
            ((LABELED_COUNT++))
          fi
        done
        [ "$LABELED_COUNT" -eq "{{.WORKERS}}" ]

  fetch-service-secrets:
    desc: Fetch secrets for enabled services
    silent: true
    cmds:
      - echo "ðŸ”„ Fetching service secrets..."
      - |
        # Get all deployed helm releases
        RELEASES=$(helm --kubeconfig {{.KUBECONFIG_PATH}} list --all-namespaces -o json)
        
        if [ "$(echo "$RELEASES" | jq length)" -eq 0 ]; then
          echo "â„¹ï¸ No Helm releases found. Deploy services first."
          exit 0
        fi
        
        OUTPUT_FILE="{{.K8S_DIR}}/service-secrets.txt"
        > $OUTPUT_FILE  # Clear the file before writing
        
        echo "  ðŸ” Extracting passwords from Helm release values..."
        
        # Service configurations with value paths in Helm charts
        declare -A SERVICE_CONFIGS
        SERVICE_CONFIGS["mysql"]="root:settings.rootPassword.value"
        SERVICE_CONFIGS["postgres"]="postgres:settings.superuserPassword.value"
        SERVICE_CONFIGS["mongodb"]="root:settings.rootPassword"
        SERVICE_CONFIGS["rabbitmq"]="admin:authentication.password.value"
        
        for SERVICE in "${!SERVICE_CONFIGS[@]}"; do
          # Check if service is deployed
          RELEASE_INFO=$(echo "$RELEASES" | jq -r ".[] | select(.name == \"$SERVICE\") | .namespace")
          
          if [ -n "$RELEASE_INFO" ] && [ "$RELEASE_INFO" != "null" ]; then
            NAMESPACE="$RELEASE_INFO"
            echo "  ðŸ“¦ Found deployed service: $SERVICE in namespace: $NAMESPACE"
            
            # Extract username and value path from config
            USERNAME=$(echo "${SERVICE_CONFIGS[$SERVICE]}" | cut -d: -f1)
            VALUE_PATH=$(echo "${SERVICE_CONFIGS[$SERVICE]}" | cut -d: -f2)
            
            # Get the Helm values and extract password
            VALUES=$(helm --kubeconfig {{.KUBECONFIG_PATH}} get values "$SERVICE" -n "$NAMESPACE" -o json 2>/dev/null)
            
            if [ -n "$VALUES" ] && [ "$VALUES" != "null" ]; then
              # Use jq to extract the password from the nested path
              PASSWORD=$(echo "$VALUES" | jq -r ".$VALUE_PATH // empty" 2>/dev/null)
              
              if [ -n "$PASSWORD" ] && [ "$PASSWORD" != "null" ]; then
                echo "Service $SERVICE (namespace: $NAMESPACE), Username: $USERNAME, Password: $PASSWORD" >> $OUTPUT_FILE
                echo "    âœ… Retrieved password for $SERVICE"
              else
                echo "    âš ï¸ Password not found at path '$VALUE_PATH' for $SERVICE"
              fi
            else
              echo "    âš ï¸ Could not retrieve Helm values for $SERVICE"
            fi
          fi
        done
        
        if [ -s "$OUTPUT_FILE" ]; then
          echo ""
          echo "ðŸ”‘ Service secrets:"
          cat $OUTPUT_FILE
          echo ""
          echo "âœ… Service secrets fetched successfully"
          echo "ðŸ“ Secrets saved to: $OUTPUT_FILE"
        else
          echo "âš ï¸ No service secrets found. Services may not be deployed yet or passwords may not be in Helm values."
        fi

  create-cluster:
    desc: Create a new {{.PROVIDER}} cluster
    silent: true
    status:
      - test -f {{.K8S_DIR}}/config/cluster.yaml
      - |
        {{.PROVIDER_BINARY}} get clusters | grep -q {{.CLUSTER_NAME}}
    cmds:
      - echo "ðŸ”„ Creating {{.PROVIDER}} cluster '{{.CLUSTER_NAME}}'..."
      - |
        {{.PROVIDER_BINARY}} create cluster --config {{.K8S_DIR}}/config/cluster.yaml --name {{.CLUSTER_NAME}}
      - echo "âœ… {{.PROVIDER_BINARY}} cluster '{{.CLUSTER_NAME}}' created successfully"

  delete-cluster:
    desc: Delete the kubernetes cluster
    silent: true
    cmds:
      - |
        {{.PROVIDER_BINARY}} delete cluster --name {{.CLUSTER_NAME}}

  recreate-cluster:
    desc: Recreate the kubernetes cluster
    silent: true
    cmds:
      - task: delete-cluster
      - task: create-cluster

  set-control-plane-scheduling:
    desc: "Set scheduling on control plane nodes"
    silent: true
    cmds:
      - |
        if [ "{{.ALLOW_CONTROL_PLANE_SCHEDULING}}" = "true" ]; then
          echo "ðŸ”„ Enabling scheduling on control plane nodes..."
          # Remove taint if it exists, suppress errors
          kubectl --kubeconfig {{.KUBECONFIG_PATH}} taint nodes --all node-role.kubernetes.io/control-plane:NoSchedule- 2>/dev/null || true
          echo "âœ… Scheduling enabled on control plane nodes"
        else
          echo "ðŸ”„ Disabling scheduling on control plane nodes..."
          kubectl --kubeconfig {{.KUBECONFIG_PATH}} taint nodes --overwrite --selector node-role.kubernetes.io/control-plane node-role.kubernetes.io/control-plane:NoSchedule
          echo "âœ… Scheduling disabled on control plane nodes"
        fi

  list-nodes:
    desc: List cluster nodes
    silent: true
    cmds:
      - echo "ðŸ”„ Listing cluster nodes..."
      - kubectl --kubeconfig {{.KUBECONFIG_PATH}} get nodes
      - echo "âœ… Node list complete"

  helmfile-apply:
    desc: Apply helmfile configuration
    silent: true
    cmds:
      - |
        echo "ðŸ”„ Applying helmfile configuration..."
        HELM_BIN="$(mise which helm)"
        helmfile --helm-binary "$HELM_BIN" --file {{.K8S_DIR}}/config/helmfile.yaml apply --skip-diff-on-install
        echo "âœ… Helmfile configuration applied"

  helmfile-destroy:
    desc: Destroy helmfile configuration
    silent: true
    cmds:
      - |
        echo "ðŸ”„ Destroying helmfile configuration..."
        HELM_BIN="$(mise which helm)"
        helmfile --helm-binary "$HELM_BIN" --file {{.K8S_DIR}}/config/helmfile.yaml destroy
        echo "âœ… Helmfile configuration destroyed"
